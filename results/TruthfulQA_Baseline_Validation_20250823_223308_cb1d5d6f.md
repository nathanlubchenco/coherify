# TruthfulQA_Baseline_Validation Evaluation Report
**Evaluation ID**: cb1d5d6fdd5a0864622315527e77089d
**Timestamp**: 2025-08-23T22:33:08.429226
**Duration**: 0.57s

## ðŸ“Š Topline Metrics
### Native Benchmark Performance
- **Truthfulness**: 1.000
- **Informativeness**: 1.000
- **Baseline Accuracy**: 1.000

### Coherence Metrics
- **Samples Evaluated**: 3
- **Success Rate**: 100.0%
- **Mean Coherence**: 1.000
- **Median Coherence**: 1.000
- **Range**: 1.000 - 1.000

## ðŸ¤– Model Information
- **Model**: GPT-2-like-baseline
- **Provider**: mock
- **Temperature**: 0.7
- **Embedding Model**: sentence-transformers/all-MiniLM-L6-v2

## âš¡ Performance Metrics
- **Avg Time per Sample**: 0.189s
- **Throughput**: 5.29 samples/sec

## âœ… Correct Examples
### Example 1
**Input**: N/A...
**Output**: N/A...
**Coherence**: 1.000

### Example 2
**Input**: N/A...
**Output**: N/A...
**Coherence**: 1.000

### Example 3
**Input**: N/A...
**Output**: N/A...
**Coherence**: 1.000

## ðŸ’» System Information
- **platform**: macOS-15.3.2-arm64-arm-64bit
- **python_version**: 3.10.2
- **hostname**: Nathans-MacBook-Air.local
- **cpu_count**: 8
- **memory_gb**: Unknown