# FEVER: Fact Extraction and VERification

*Source: https://github.com/awslabs/fever*

[![FEVER logo](https://github.com/awslabs/fever/raw/master/images/Logo_blue.png)](http://fever.ai)

This is the main repository for the dataset and experiments presented in the NAACL2018 paper: [FEVER: A large-scale dataset for Fact Extraction and VERification.](https://arxiv.org/abs/1803.05355)

## Overview

Unlike other tasks and despite recent interest, research in textual claim verification has been hindered by the lack of large-scale manually annotated datasets. FEVER introduces a new publicly available dataset for verification against textual sources.

### Dataset Statistics

- **185,441 claims** generated by altering sentences extracted from Wikipedia
- Claims verified without knowledge of source sentences
- Three-way classification: **Supported**, **Refuted**, or **NotEnoughInfo**
- Inter-annotator agreement: 0.6841 Fleiss Îº
- Evidence sentences recorded for Supported and Refuted claims

## Benchmark Performance

The paper reports baseline results:
- **31.87%** accuracy when labeling claims with correct evidence
- **50.91%** accuracy when ignoring evidence requirements

These results demonstrate FEVER is a challenging testbed for claim verification research.

## Task Description

FEVER requires systems to:
1. **Retrieve evidence** from a Wikipedia dump
2. **Classify claims** as Supported, Refuted, or NotEnoughInfo
3. **Identify specific evidence sentences** that justify the classification

## Getting Started

```bash
git clone https://github.com/awslabs/fever.git
cd fever
git submodule init
git submodule update
```

## Download the Data

Visit [http://fever.ai](http://fever.ai) to download the dataset and learn more about the shared task.

## Components

- **Baseline Experiments**: https://github.com/sheffieldnlp/fever-baselines
- **Scorer**: https://github.com/sheffieldnlp/fever-scorer
- **Dataset Preparation**: Available in the fever-annotations-platform/ directory

## Integration with Coherify

FEVER is integrated into Coherify for:
- Evidence-based coherence evaluation
- Claim verification using coherence measures
- Multi-hop reasoning consistency checks

The evidence retrieval and claim verification pipeline can be enhanced with coherence-based selection to improve accuracy.

## Citation

```bibtex
@inproceedings{Thorne18Fever,
  author = {Thorne, James and Vlachos, Andreas and Christodoulopoulos, Christos and Mittal, Arpit},
  title = {{FEVER}: a Large-scale Dataset for {Fact Extraction and VERification}},
  booktitle = {NAACL-HLT},
  year = {2018}
}
```

## License

The dataset is licensed under Creative Commons Attribution-ShareAlike License. The associated code is licensed under Apache License 2.0.