{
  "models": {
    "default": {
      "provider": "openai",
      "model": "gpt-4o-mini",
      "temperature": 0.7,
      "max_tokens": 1000
    },
    "gpt4-mini": {
      "provider": "openai", 
      "model": "gpt-4o-mini",
      "temperature": 0.7,
      "max_tokens": 1000
    },
    "gpt4": {
      "provider": "openai",
      "model": "gpt-4o",
      "temperature": 0.7,
      "max_tokens": 1000
    },
    "gpt4o": {
      "provider": "openai",
      "model": "gpt-4o",
      "temperature": 0.7,
      "max_tokens": 1000
    },
    "claude": {
      "provider": "anthropic",
      "model": "claude-3-sonnet-20240229",
      "temperature": 0.7,
      "max_tokens": 1000
    }
  },
  "benchmarks": {
    "truthfulqa": {
      "sample_size": 50,
      "evaluation_mode": "generation",
      "use_api_enhancement": true,
      "coherence_measures": [
        "SemanticCoherence",
        "HybridCoherence",
        "APIEnhancedHybridCoherence"
      ]
    },
    "fever": {
      "sample_size": 100,
      "evaluation_mode": "classification"
    },
    "selfcheckgpt": {
      "sample_size": 50,
      "evaluation_mode": "generation",
      "num_generations": 5
    }
  },
  "api_settings": {
    "use_temperature_variance": true,
    "temperature_range": [
      0.1,
      0.3,
      0.5,
      0.7,
      1.0,
      1.3,
      1.5
    ],
    "temperature_range_adaptive": {
      "easy": [0.1, 0.3, 0.5],
      "medium": [0.3, 0.7, 1.0],
      "hard": [0.5, 1.0, 1.5, 2.0]
    },
    "num_generations_per_prompt": 2,
    "enable_confidence_scoring": true
  }
}